{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['sci.med', 'sci.space'] \n",
    "twenty_sci_news=fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: flb@flb.optiplan.fi (\"F.Baube[tm]\")\n",
      "Subject: Vandalizing the sky\n",
      "X-Added: Forwarded by Space Digest\n",
      "Organization: [via International Space University]\n",
      "Original-Sender: isu@VACATION.VENARI.CS.CMU.EDU\n",
      "Distribution: sci\n",
      "Lines: 12\n",
      "\n",
      "From: \"Phil G. Fraering\" <pgf@srl03.cacs.usl.edu>\n",
      "> \n",
      "> Finally: this isn't the Bronze Age, [..]\n",
      "> please try to remember that there are more human activities than\n",
      "> those practiced by the Warrior Caste, the Farming Caste, and the\n",
      "> Priesthood.\n",
      "\n",
      "Right, the Profiting Caste is blessed by God, and may \n",
      " freely blare its presence in the evening twilight ..\n",
      "\n",
      "-- \n",
      "* Fred Baube (tm)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_sci_news.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/home/pi/scikit_learn_data/20news_home/20news-bydate-train/sci.space/61116',\n",
       "       '/home/pi/scikit_learn_data/20news_home/20news-bydate-train/sci.med/58122',\n",
       "       '/home/pi/scikit_learn_data/20news_home/20news-bydate-train/sci.med/58903',\n",
       "       ...,\n",
       "       '/home/pi/scikit_learn_data/20news_home/20news-bydate-train/sci.space/60774',\n",
       "       '/home/pi/scikit_learn_data/20news_home/20news-bydate-train/sci.space/60954',\n",
       "       '/home/pi/scikit_learn_data/20news_home/20news-bydate-train/sci.med/58911'],\n",
       "      dtype='<U89')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_sci_news.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(twenty_sci_news.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1187, 25638)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "word_count = count_vect.fit_transform(twenty_sci_news.data)\n",
    "word_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10778)\t1\n",
      "  (0, 23849)\t1\n",
      "  (0, 9796)\t1\n",
      "  (0, 12716)\t1\n",
      "  (0, 18586)\t1\n",
      "  (0, 13384)\t1\n",
      "  (0, 5134)\t1\n",
      "  (0, 10785)\t1\n",
      "  (0, 15246)\t1\n",
      "  (0, 11330)\t1\n",
      "  (0, 5148)\t1\n",
      "  (0, 13318)\t1\n",
      "  (0, 18744)\t1\n",
      "  (0, 20110)\t1\n",
      "  (0, 18642)\t1\n",
      "  (0, 3808)\t2\n",
      "  (0, 10188)\t1\n",
      "  (0, 6017)\t3\n",
      "  (0, 24930)\t1\n",
      "  (0, 18474)\t1\n",
      "  (0, 23241)\t1\n",
      "  (0, 23129)\t1\n",
      "  (0, 3191)\t1\n",
      "  (0, 12362)\t1\n",
      "  (0, 15968)\t1\n",
      "  :\t:\n",
      "  (0, 7646)\t1\n",
      "  (0, 24547)\t1\n",
      "  (0, 24415)\t1\n",
      "  (0, 13359)\t1\n",
      "  (0, 20909)\t1\n",
      "  (0, 17235)\t1\n",
      "  (0, 24151)\t1\n",
      "  (0, 13158)\t1\n",
      "  (0, 24626)\t1\n",
      "  (0, 17217)\t1\n",
      "  (0, 8438)\t1\n",
      "  (0, 21686)\t2\n",
      "  (0, 5650)\t3\n",
      "  (0, 10713)\t1\n",
      "  (0, 3233)\t1\n",
      "  (0, 21382)\t1\n",
      "  (0, 23137)\t7\n",
      "  (0, 24461)\t1\n",
      "  (0, 22345)\t1\n",
      "  (0, 23381)\t2\n",
      "  (0, 4762)\t2\n",
      "  (0, 10341)\t1\n",
      "  (0, 17170)\t1\n",
      "  (0, 10501)\t2\n",
      "  (0, 10827)\t2\n"
     ]
    }
   ],
   "source": [
    "print(word_count[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word \"fred\" appears 1 times\n",
      "Word \"twilight\" appears 1 times\n",
      "Word \"evening\" appears 1 times\n",
      "Word \"in\" appears 1 times\n",
      "Word \"presence\" appears 1 times\n",
      "Word \"its\" appears 1 times\n",
      "Word \"blare\" appears 1 times\n",
      "Word \"freely\" appears 1 times\n",
      "Word \"may\" appears 1 times\n",
      "Word \"god\" appears 1 times\n",
      "Word \"blessed\" appears 1 times\n",
      "Word \"is\" appears 1 times\n",
      "Word \"profiting\" appears 1 times\n",
      "Word \"right\" appears 1 times\n",
      "Word \"priesthood\" appears 1 times\n",
      "Word \"and\" appears 2 times\n",
      "Word \"farming\" appears 1 times\n",
      "Word \"caste\" appears 3 times\n",
      "Word \"warrior\" appears 1 times\n",
      "Word \"practiced\" appears 1 times\n",
      "Word \"those\" appears 1 times\n",
      "Word \"than\" appears 1 times\n",
      "Word \"activities\" appears 1 times\n",
      "Word \"human\" appears 1 times\n",
      "Word \"more\" appears 1 times\n",
      "Word \"are\" appears 1 times\n",
      "Word \"there\" appears 1 times\n",
      "Word \"that\" appears 1 times\n",
      "Word \"remember\" appears 1 times\n",
      "Word \"to\" appears 1 times\n",
      "Word \"try\" appears 1 times\n",
      "Word \"please\" appears 1 times\n",
      "Word \"age\" appears 1 times\n",
      "Word \"bronze\" appears 1 times\n",
      "Word \"isn\" appears 1 times\n",
      "Word \"this\" appears 1 times\n",
      "Word \"finally\" appears 1 times\n",
      "Word \"usl\" appears 1 times\n",
      "Word \"cacs\" appears 1 times\n",
      "Word \"srl03\" appears 1 times\n",
      "Word \"pgf\" appears 1 times\n",
      "Word \"fraering\" appears 1 times\n",
      "Word \"phil\" appears 1 times\n",
      "Word \"12\" appears 1 times\n",
      "Word \"lines\" appears 1 times\n",
      "Word \"sci\" appears 1 times\n",
      "Word \"distribution\" appears 1 times\n",
      "Word \"edu\" appears 2 times\n",
      "Word \"cmu\" appears 1 times\n",
      "Word \"cs\" appears 1 times\n",
      "Word \"venari\" appears 1 times\n",
      "Word \"vacation\" appears 1 times\n",
      "Word \"isu\" appears 1 times\n",
      "Word \"sender\" appears 1 times\n",
      "Word \"original\" appears 1 times\n",
      "Word \"university\" appears 1 times\n",
      "Word \"international\" appears 1 times\n",
      "Word \"via\" appears 1 times\n",
      "Word \"organization\" appears 1 times\n",
      "Word \"digest\" appears 1 times\n",
      "Word \"space\" appears 2 times\n",
      "Word \"by\" appears 3 times\n",
      "Word \"forwarded\" appears 1 times\n",
      "Word \"added\" appears 1 times\n",
      "Word \"sky\" appears 1 times\n",
      "Word \"the\" appears 7 times\n",
      "Word \"vandalizing\" appears 1 times\n",
      "Word \"subject\" appears 1 times\n",
      "Word \"tm\" appears 2 times\n",
      "Word \"baube\" appears 2 times\n",
      "Word \"fi\" appears 1 times\n",
      "Word \"optiplan\" appears 1 times\n",
      "Word \"flb\" appears 2 times\n",
      "Word \"from\" appears 2 times\n"
     ]
    }
   ],
   "source": [
    "word_list = count_vect.get_feature_names()\n",
    "for n in word_count[0].indices:\n",
    "    print ('Word \"%s\" appears %i times' % (word_list[n], word_count[0, n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word \"fred\" has frequency 0.011\n",
      "Word \"twilight\" has frequency 0.011\n",
      "Word \"evening\" has frequency 0.011\n",
      "Word \"in\" has frequency 0.011\n",
      "Word \"presence\" has frequency 0.011\n",
      "Word \"its\" has frequency 0.011\n",
      "Word \"blare\" has frequency 0.011\n",
      "Word \"freely\" has frequency 0.011\n",
      "Word \"may\" has frequency 0.011\n",
      "Word \"god\" has frequency 0.011\n",
      "Word \"blessed\" has frequency 0.011\n",
      "Word \"is\" has frequency 0.011\n",
      "Word \"profiting\" has frequency 0.011\n",
      "Word \"right\" has frequency 0.011\n",
      "Word \"priesthood\" has frequency 0.011\n",
      "Word \"and\" has frequency 0.022\n",
      "Word \"farming\" has frequency 0.011\n",
      "Word \"caste\" has frequency 0.033\n",
      "Word \"warrior\" has frequency 0.011\n",
      "Word \"practiced\" has frequency 0.011\n",
      "Word \"those\" has frequency 0.011\n",
      "Word \"than\" has frequency 0.011\n",
      "Word \"activities\" has frequency 0.011\n",
      "Word \"human\" has frequency 0.011\n",
      "Word \"more\" has frequency 0.011\n",
      "Word \"are\" has frequency 0.011\n",
      "Word \"there\" has frequency 0.011\n",
      "Word \"that\" has frequency 0.011\n",
      "Word \"remember\" has frequency 0.011\n",
      "Word \"to\" has frequency 0.011\n",
      "Word \"try\" has frequency 0.011\n",
      "Word \"please\" has frequency 0.011\n",
      "Word \"age\" has frequency 0.011\n",
      "Word \"bronze\" has frequency 0.011\n",
      "Word \"isn\" has frequency 0.011\n",
      "Word \"this\" has frequency 0.011\n",
      "Word \"finally\" has frequency 0.011\n",
      "Word \"usl\" has frequency 0.011\n",
      "Word \"cacs\" has frequency 0.011\n",
      "Word \"srl03\" has frequency 0.011\n",
      "Word \"pgf\" has frequency 0.011\n",
      "Word \"fraering\" has frequency 0.011\n",
      "Word \"phil\" has frequency 0.011\n",
      "Word \"12\" has frequency 0.011\n",
      "Word \"lines\" has frequency 0.011\n",
      "Word \"sci\" has frequency 0.011\n",
      "Word \"distribution\" has frequency 0.011\n",
      "Word \"edu\" has frequency 0.022\n",
      "Word \"cmu\" has frequency 0.011\n",
      "Word \"cs\" has frequency 0.011\n",
      "Word \"venari\" has frequency 0.011\n",
      "Word \"vacation\" has frequency 0.011\n",
      "Word \"isu\" has frequency 0.011\n",
      "Word \"sender\" has frequency 0.011\n",
      "Word \"original\" has frequency 0.011\n",
      "Word \"university\" has frequency 0.011\n",
      "Word \"international\" has frequency 0.011\n",
      "Word \"via\" has frequency 0.011\n",
      "Word \"organization\" has frequency 0.011\n",
      "Word \"digest\" has frequency 0.011\n",
      "Word \"space\" has frequency 0.022\n",
      "Word \"by\" has frequency 0.033\n",
      "Word \"forwarded\" has frequency 0.011\n",
      "Word \"added\" has frequency 0.011\n",
      "Word \"sky\" has frequency 0.011\n",
      "Word \"the\" has frequency 0.077\n",
      "Word \"vandalizing\" has frequency 0.011\n",
      "Word \"subject\" has frequency 0.011\n",
      "Word \"tm\" has frequency 0.022\n",
      "Word \"baube\" has frequency 0.022\n",
      "Word \"fi\" has frequency 0.011\n",
      "Word \"optiplan\" has frequency 0.011\n",
      "Word \"flb\" has frequency 0.022\n",
      "Word \"from\" has frequency 0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vect = TfidfVectorizer(use_idf=False, norm='l1')\n",
    "word_freq = tf_vect.fit_transform(twenty_sci_news.data)\n",
    "word_list = tf_vect.get_feature_names()\n",
    "for n in word_freq[0].indices:\n",
    "    print ('Word \"%s\" has frequency %0.3f' % (word_list[n], word_freq[0,n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word \"fred\" has frequency 0.089\n",
      "Word \"twilight\" has frequency 0.139\n",
      "Word \"evening\" has frequency 0.113\n",
      "Word \"in\" has frequency 0.024\n",
      "Word \"presence\" has frequency 0.119\n",
      "Word \"its\" has frequency 0.061\n",
      "Word \"blare\" has frequency 0.150\n",
      "Word \"freely\" has frequency 0.119\n",
      "Word \"may\" has frequency 0.054\n",
      "Word \"god\" has frequency 0.119\n",
      "Word \"blessed\" has frequency 0.150\n",
      "Word \"is\" has frequency 0.026\n",
      "Word \"profiting\" has frequency 0.150\n",
      "Word \"right\" has frequency 0.068\n",
      "Word \"priesthood\" has frequency 0.144\n",
      "Word \"and\" has frequency 0.049\n",
      "Word \"farming\" has frequency 0.144\n",
      "Word \"caste\" has frequency 0.433\n",
      "Word \"warrior\" has frequency 0.144\n",
      "Word \"practiced\" has frequency 0.132\n",
      "Word \"those\" has frequency 0.060\n",
      "Word \"than\" has frequency 0.052\n",
      "Word \"activities\" has frequency 0.091\n",
      "Word \"human\" has frequency 0.084\n",
      "Word \"more\" has frequency 0.046\n",
      "Word \"are\" has frequency 0.035\n",
      "Word \"there\" has frequency 0.039\n",
      "Word \"that\" has frequency 0.027\n",
      "Word \"remember\" has frequency 0.077\n",
      "Word \"to\" has frequency 0.023\n",
      "Word \"try\" has frequency 0.073\n",
      "Word \"please\" has frequency 0.071\n",
      "Word \"age\" has frequency 0.092\n",
      "Word \"bronze\" has frequency 0.144\n",
      "Word \"isn\" has frequency 0.073\n",
      "Word \"this\" has frequency 0.031\n",
      "Word \"finally\" has frequency 0.097\n",
      "Word \"usl\" has frequency 0.112\n",
      "Word \"cacs\" has frequency 0.114\n",
      "Word \"srl03\" has frequency 0.121\n",
      "Word \"pgf\" has frequency 0.114\n",
      "Word \"fraering\" has frequency 0.113\n",
      "Word \"phil\" has frequency 0.102\n",
      "Word \"12\" has frequency 0.076\n",
      "Word \"lines\" has frequency 0.022\n",
      "Word \"sci\" has frequency 0.067\n",
      "Word \"distribution\" has frequency 0.053\n",
      "Word \"edu\" has frequency 0.059\n",
      "Word \"cmu\" has frequency 0.081\n",
      "Word \"cs\" has frequency 0.055\n",
      "Word \"venari\" has frequency 0.103\n",
      "Word \"vacation\" has frequency 0.099\n",
      "Word \"isu\" has frequency 0.099\n",
      "Word \"sender\" has frequency 0.093\n",
      "Word \"original\" has frequency 0.085\n",
      "Word \"university\" has frequency 0.045\n",
      "Word \"international\" has frequency 0.081\n",
      "Word \"via\" has frequency 0.083\n",
      "Word \"organization\" has frequency 0.022\n",
      "Word \"digest\" has frequency 0.095\n",
      "Word \"space\" has frequency 0.098\n",
      "Word \"by\" has frequency 0.120\n",
      "Word \"forwarded\" has frequency 0.096\n",
      "Word \"added\" has frequency 0.088\n",
      "Word \"sky\" has frequency 0.091\n",
      "Word \"the\" has frequency 0.158\n",
      "Word \"vandalizing\" has frequency 0.103\n",
      "Word \"subject\" has frequency 0.022\n",
      "Word \"tm\" has frequency 0.219\n",
      "Word \"baube\" has frequency 0.264\n",
      "Word \"fi\" has frequency 0.110\n",
      "Word \"optiplan\" has frequency 0.132\n",
      "Word \"flb\" has frequency 0.264\n",
      "Word \"from\" has frequency 0.043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer() #Default: use_idf=True\n",
    "word_tfidf = tfidf_vect.fit_transform(twenty_sci_news.data)\n",
    "word_list = tfidf_vect.get_feature_names()\n",
    "for n in word_freq[0].indices:\n",
    "    print ('Word \"%s\" has tf-idf %0.3f' % (word_list[n], word_tfidf[0,n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we love data science', 'data science is hard']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1 = 'we love data science'\n",
    "text_2 = 'data science is hard'\n",
    "documents = [text_1, text_2]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word list=  ['data', 'hard', 'is', 'love', 'science', 'we']\n",
      "text_1 is described with ['science(1)', 'data(1)', 'love(1)', 'we(1)']\n"
     ]
    }
   ],
   "source": [
    "# that is what we say above, the default one\n",
    "count_vect_1_grams = CountVectorizer(ngram_range=(1, 1), stop_words=[], min_df=1)\n",
    "word_count = count_vect_1_grams.fit_transform(documents)\n",
    "word_list = count_vect_1_grams.get_feature_names()\n",
    "print (\"Word list= \", word_list)\n",
    "print (\"text_1 is described with\", [word_list[n]+\"(\" + str(word_count[0, n])+\")\" for n in word_count[0].indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word list=  ['data science', 'is hard', 'love data', 'science is', 'we love']\n",
      "text_1 is described with ['data science(1)', 'love data(1)', 'we love(1)']\n"
     ]
    }
   ],
   "source": [
    "# now a bi-gram count vectorizer\n",
    "count_vect_1_grams = CountVectorizer(ngram_range=(2,2))\n",
    "word_count = count_vect_1_grams.fit_transform(documents)\n",
    "word_list = count_vect_1_grams.get_feature_names()\n",
    "print (\"Word list= \", word_list)\n",
    "print (\"text_1 is described with\", [word_list[n]+\"(\"+str(word_count[0,n])+\")\" for n in word_count[0].indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word list=  ['data', 'data science', 'hard', 'is', 'is hard', 'love', 'love data', 'science', 'science is', 'we', 'we love']\n",
      "text_1 is described with ['data science(1)', 'love data(1)', 'we love(1)', 'science(1)', 'data(1)', 'love(1)', 'we(1)']\n"
     ]
    }
   ],
   "source": [
    "# now a uni- and bi-gram count vectorizer\n",
    "count_vect_1_grams = CountVectorizer(ngram_range=(1,2))\n",
    "word_count = count_vect_1_grams.fit_transform(documents)\n",
    "word_list = count_vect_1_grams.get_feature_names()\n",
    "print (\"Word list= \", word_list)\n",
    "print (\"text_1 is described with\", [word_list[n]+\"(\"+str(word_count[0,n])+\")\" for n in word_count[0].indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1187, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hash_vect = HashingVectorizer(n_features=1000)\n",
    "word_hashed = hash_vect.fit_transform(twenty_sci_news.data)\n",
    "word_hashed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
